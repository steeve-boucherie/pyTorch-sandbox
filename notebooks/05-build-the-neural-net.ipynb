{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Neural Network\n",
    "This notebook follows the step from the [Build the Neural Network](https://docs.pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html) of the pyTorch offical documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Device for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "device = \"cpu\"  # ROCm does not work with my GPU\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([2])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "input_image = torch.rand(3,28,28)\n",
    "print(input_image.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Flattens a contiguous range of dims into a tensor.\n",
      "\n",
      "    For use with :class:`~nn.Sequential`, see :meth:`torch.flatten` for details.\n",
      "\n",
      "    Shape:\n",
      "        - Input: :math:`(*, S_{\\text{start}},..., S_{i}, ..., S_{\\text{end}}, *)`,'\n",
      "          where :math:`S_{i}` is the size at dimension :math:`i` and :math:`*` means any\n",
      "          number of dimensions including none.\n",
      "        - Output: :math:`(*, \\prod_{i=\\text{start}}^{\\text{end}} S_{i}, *)`.\n",
      "\n",
      "    Args:\n",
      "        start_dim: first dim to flatten (default = 1).\n",
      "        end_dim: last dim to flatten (default = -1).\n",
      "\n",
      "    Examples::\n",
      "        >>> input = torch.randn(32, 1, 5, 5)\n",
      "        >>> # With default parameters\n",
      "        >>> m = nn.Flatten()\n",
      "        >>> output = m(input)\n",
      "        >>> output.size()\n",
      "        torch.Size([32, 25])\n",
      "        >>> # With non-default parameters\n",
      "        >>> m = nn.Flatten(0, 2)\n",
      "        >>> output = m(input)\n",
      "        >>> output.size()\n",
      "        torch.Size([160, 5])\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(nn.Flatten.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2352])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Flatten(0)(input_image).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 784])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Flatten(1)(input_image).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 28, 28])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Flatten(2)(input_image).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Linear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applies an affine linear transformation to the incoming data: :math:`y = xA^T + b`.\n",
      "\n",
      "    This module supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
      "\n",
      "    On certain ROCm devices, when using float16 inputs this module will use :ref:`different precision<fp16_on_mi200>` for backward.\n",
      "\n",
      "    Args:\n",
      "        in_features: size of each input sample\n",
      "        out_features: size of each output sample\n",
      "        bias: If set to ``False``, the layer will not learn an additive bias.\n",
      "            Default: ``True``\n",
      "\n",
      "    Shape:\n",
      "        - Input: :math:`(*, H_\\text{in})` where :math:`*` means any number of\n",
      "          dimensions including none and :math:`H_\\text{in} = \\text{in\\_features}`.\n",
      "        - Output: :math:`(*, H_\\text{out})` where all but the last dimension\n",
      "          are the same shape as the input and :math:`H_\\text{out} = \\text{out\\_features}`.\n",
      "\n",
      "    Attributes:\n",
      "        weight: the learnable weights of the module of shape\n",
      "            :math:`(\\text{out\\_features}, \\text{in\\_features})`. The values are\n",
      "            initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`, where\n",
      "            :math:`k = \\frac{1}{\\text{in\\_features}}`\n",
      "        bias:   the learnable bias of the module of shape :math:`(\\text{out\\_features})`.\n",
      "                If :attr:`bias` is ``True``, the values are initialized from\n",
      "                :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
      "                :math:`k = \\frac{1}{\\text{in\\_features}}`\n",
      "\n",
      "    Examples::\n",
      "\n",
      "        >>> m = nn.Linear(20, 30)\n",
      "        >>> input = torch.randn(128, 20)\n",
      "        >>> output = m(input)\n",
      "        >>> print(output.size())\n",
      "        torch.Size([128, 30])\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(nn.Linear.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0155,  0.0231,  0.0092,  ...,  0.0034,  0.0149, -0.0177],\n",
       "        [ 0.0254,  0.0017, -0.0072,  ..., -0.0033,  0.0132, -0.0324],\n",
       "        [ 0.0349, -0.0247,  0.0112,  ..., -0.0285,  0.0160, -0.0226],\n",
       "        ...,\n",
       "        [ 0.0002,  0.0092,  0.0020,  ..., -0.0093,  0.0025,  0.0267],\n",
       "        [-0.0142, -0.0116,  0.0126,  ...,  0.0153, -0.0225, -0.0186],\n",
       "        [ 0.0051,  0.0236, -0.0126,  ..., -0.0268, -0.0228, -0.0330]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2747,  0.1350, -0.8865, -0.1894, -0.3170,  0.0018, -0.1592,  0.7772,\n",
       "         0.3894,  0.3154], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = nn.Linear(in_features=10,  out_features=10)\n",
    "\n",
    "x = torch.rand(10)\n",
    "y = layer(x)\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.2960, -0.0574, -0.1726,  0.0907,  0.2353, -0.3092,  0.1125, -0.0738,\n",
       "          0.0952, -0.1898],\n",
       "        [ 0.2573,  0.0363,  0.1349, -0.2025,  0.2598, -0.0496,  0.2254,  0.0152,\n",
       "          0.2921,  0.0238],\n",
       "        [ 0.0209, -0.1672, -0.3038, -0.2100, -0.1875, -0.2619, -0.2993, -0.0018,\n",
       "          0.1180,  0.0061],\n",
       "        [ 0.2653, -0.2538, -0.1997,  0.0977,  0.0902, -0.0793, -0.1537, -0.0416,\n",
       "         -0.2008,  0.0539],\n",
       "        [-0.0811, -0.1934, -0.1184,  0.2595, -0.0915,  0.0333,  0.0893,  0.1553,\n",
       "         -0.1087, -0.0891],\n",
       "        [ 0.1283, -0.1995, -0.1355,  0.2478,  0.3001, -0.2241,  0.1366, -0.2366,\n",
       "         -0.0186,  0.1866],\n",
       "        [ 0.0400, -0.2314,  0.3074, -0.2242, -0.1401, -0.1783, -0.2405, -0.1507,\n",
       "          0.1855,  0.0565],\n",
       "        [ 0.0750,  0.1534, -0.0423,  0.0825,  0.1479,  0.0587, -0.2124,  0.3001,\n",
       "          0.0501,  0.1326],\n",
       "        [-0.1835,  0.0153, -0.1971,  0.0915,  0.1285,  0.1167, -0.1436,  0.1649,\n",
       "          0.1573, -0.1137],\n",
       "        [-0.1000, -0.1192, -0.3161, -0.0879,  0.2126,  0.1760,  0.0947,  0.3136,\n",
       "         -0.1765, -0.3147]], requires_grad=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applies the rectified linear unit function element-wise.\n",
      "\n",
      "    :math:`\\text{ReLU}(x) = (x)^+ = \\max(0, x)`\n",
      "\n",
      "    Args:\n",
      "        inplace: can optionally do the operation in-place. Default: ``False``\n",
      "\n",
      "    Shape:\n",
      "        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n",
      "        - Output: :math:`(*)`, same shape as the input.\n",
      "\n",
      "    .. image:: ../scripts/activation_images/ReLU.png\n",
      "\n",
      "    Examples::\n",
      "\n",
      "        >>> m = nn.ReLU()\n",
      "        >>> input = torch.randn(2)\n",
      "        >>> output = m(input)\n",
      "\n",
      "\n",
      "      An implementation of CReLU - https://arxiv.org/abs/1603.05201\n",
      "\n",
      "        >>> m = nn.ReLU()\n",
      "        >>> input = torch.randn(2).unsqueeze(0)\n",
      "        >>> output = torch.cat((m(input), m(-input)))\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(nn.ReLU.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 20])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.ReLU()(hidden1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 20])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A sequential container.\n",
      "\n",
      "    Modules will be added to it in the order they are passed in the\n",
      "    constructor. Alternatively, an ``OrderedDict`` of modules can be\n",
      "    passed in. The ``forward()`` method of ``Sequential`` accepts any\n",
      "    input and forwards it to the first module it contains. It then\n",
      "    \"chains\" outputs to inputs sequentially for each subsequent module,\n",
      "    finally returning the output of the last module.\n",
      "\n",
      "    The value a ``Sequential`` provides over manually calling a sequence\n",
      "    of modules is that it allows treating the whole container as a\n",
      "    single module, such that performing a transformation on the\n",
      "    ``Sequential`` applies to each of the modules it stores (which are\n",
      "    each a registered submodule of the ``Sequential``).\n",
      "\n",
      "    What's the difference between a ``Sequential`` and a\n",
      "    :class:`torch.nn.ModuleList`? A ``ModuleList`` is exactly what it\n",
      "    sounds like--a list for storing ``Module`` s! On the other hand,\n",
      "    the layers in a ``Sequential`` are connected in a cascading way.\n",
      "\n",
      "    Example::\n",
      "\n",
      "        # Using Sequential to create a small model. When `model` is run,\n",
      "        # input will first be passed to `Conv2d(1,20,5)`. The output of\n",
      "        # `Conv2d(1,20,5)` will be used as the input to the first\n",
      "        # `ReLU`; the output of the first `ReLU` will become the input\n",
      "        # for `Conv2d(20,64,5)`. Finally, the output of\n",
      "        # `Conv2d(20,64,5)` will be used as input to the second `ReLU`\n",
      "        model = nn.Sequential(\n",
      "                  nn.Conv2d(1,20,5),\n",
      "                  nn.ReLU(),\n",
      "                  nn.Conv2d(20,64,5),\n",
      "                  nn.ReLU()\n",
      "                )\n",
      "\n",
      "        # Using Sequential with OrderedDict. This is functionally the\n",
      "        # same as the above code\n",
      "        model = nn.Sequential(OrderedDict([\n",
      "                  ('conv1', nn.Conv2d(1,20,5)),\n",
      "                  ('relu1', nn.ReLU()),\n",
      "                  ('conv2', nn.Conv2d(20,64,5)),\n",
      "                  ('relu2', nn.ReLU())\n",
      "                ]))\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(nn.Sequential.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0067, -0.1063, -0.0076, -0.1179,  0.0656,  0.0976, -0.0157, -0.1423,\n",
       "          0.0229, -0.0053],\n",
       "        [ 0.0334, -0.0901,  0.0608, -0.2005,  0.0832,  0.0651, -0.0172, -0.1291,\n",
       "         -0.0088, -0.0482],\n",
       "        [-0.0295, -0.1323,  0.0401, -0.1519,  0.1368,  0.1490,  0.0165, -0.0654,\n",
       "          0.0090, -0.0015]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_modules = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10)\n",
    ")\n",
    "input_image = torch.rand(3,28,28)\n",
    "logits = seq_modules(input_image)\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.Softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applies the Softmax function to an n-dimensional input Tensor.\n",
      "\n",
      "    Rescales them so that the elements of the n-dimensional output Tensor\n",
      "    lie in the range [0,1] and sum to 1.\n",
      "\n",
      "    Softmax is defined as:\n",
      "\n",
      "    .. math::\n",
      "        \\text{Softmax}(x_{i}) = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}\n",
      "\n",
      "    When the input Tensor is a sparse tensor then the unspecified\n",
      "    values are treated as ``-inf``.\n",
      "\n",
      "    Shape:\n",
      "        - Input: :math:`(*)` where `*` means, any number of additional\n",
      "          dimensions\n",
      "        - Output: :math:`(*)`, same shape as the input\n",
      "\n",
      "    Returns:\n",
      "        a Tensor of the same dimension and shape as the input with\n",
      "        values in the range [0, 1]\n",
      "\n",
      "    Args:\n",
      "        dim (int): A dimension along which Softmax will be computed (so every slice\n",
      "            along dim will sum to 1).\n",
      "\n",
      "    .. note::\n",
      "        This module doesn't work directly with NLLLoss,\n",
      "        which expects the Log to be computed between the Softmax and itself.\n",
      "        Use `LogSoftmax` instead (it's faster and has better numerical properties).\n",
      "\n",
      "    Examples::\n",
      "\n",
      "        >>> m = nn.Softmax(dim=1)\n",
      "        >>> input = torch.randn(2, 3)\n",
      "        >>> output = m(input)\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(nn.Softmax.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/songz/Learning/pyTorch-sandbox/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.1024, 0.0915, 0.1010, 0.0904, 0.1087, 0.1122, 0.1002, 0.0883, 0.1041,\n",
       "         0.1012],\n",
       "        [0.1056, 0.0934, 0.1086, 0.0836, 0.1110, 0.1090, 0.1004, 0.0898, 0.1013,\n",
       "         0.0973],\n",
       "        [0.0970, 0.0875, 0.1039, 0.0858, 0.1145, 0.1159, 0.1015, 0.0935, 0.1007,\n",
       "         0.0997]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Softmax()(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/songz/Learning/pyTorch-sandbox/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Softmax()(logits).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many layers inside a neural network are parameterized, i.e. have associated weights and biases that are optimized during training. Subclassing nn.Module automatically tracks all fields defined inside your model object, and makes all parameters accessible using your model’s parameters() or named_parameters() methods.\n",
    "\n",
    "In this example, we iterate over each parameter, and print its size and a preview of its values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[-0.0356, -0.0218,  0.0281,  ...,  0.0111, -0.0255,  0.0221],\n",
      "        [-0.0320, -0.0282,  0.0293,  ..., -0.0338, -0.0199, -0.0233]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([ 0.0343, -0.0066], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[ 0.0011, -0.0437, -0.0245,  ...,  0.0176, -0.0318,  0.0113],\n",
      "        [ 0.0069,  0.0055,  0.0164,  ...,  0.0265,  0.0180,  0.0083]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([-0.0056, -0.0363], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[-0.0249, -0.0070, -0.0257,  ...,  0.0035,  0.0047, -0.0343],\n",
      "        [-0.0291, -0.0228,  0.0213,  ..., -0.0232, -0.0149,  0.0017]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([0.0016, 0.0120], grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model structure: {model}\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
